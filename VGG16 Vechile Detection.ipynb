{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60ec624",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8278,
     "status": "error",
     "timestamp": 1686498238740,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "f60ec624",
    "outputId": "f56b802f-f1d9-416b-ee91-3842140b93db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.19.3 in d:\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: tensorflow in d:\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.12)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in d:\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in d:\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install opencv-python\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install tensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      7\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/subas/Downloads/downloads1/NIT6004 Data/data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "## 1. install and Load Libraries\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('C:/Users/subas/Downloads/downloads1/Data/data')\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential, Input, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6b5fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "error",
     "timestamp": 1686497747899,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "cce6b5fa",
    "outputId": "f3170005-2bb1-4ff6-dac1-80849d77a973"
   },
   "outputs": [],
   "source": [
    "#Load and Preprocess the Data: First, you'll need to load your images from both datasets. Preprocessing typically involves resizing all images to a uniform size (as required by the input of your chosen CNN model), converting them to grayscale or other color scales (if necessary), and normalizing the pixel values to be in the range 0-1.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (28, 28))  # Resize image\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "            img = img / 255.0  # Normalize\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "vehicle_images = load_images_from_folder('C:/Users/Downloads/downloads1/Data/data/vehicles')\n",
    "\n",
    "non_vehicle_images = load_images_from_folder('C:/Users/downloads/downloads1/Data/data/non-vehicles')\n",
    "\n",
    "# Combine both images \n",
    "X = vehicle_images + non_vehicle_images\n",
    "\n",
    "# create labels (stored as list)\n",
    "#  1 means vehicle\n",
    "#  0 means non-vehicle\n",
    "\n",
    "y = [1] * len(vehicle_images) + [0] * len(non_vehicle_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1fecf",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1686497683383,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "a2a1fecf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e844de",
   "metadata": {
    "executionInfo": {
     "elapsed": 626,
     "status": "aborted",
     "timestamp": 1686497683994,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "10e844de"
   },
   "outputs": [],
   "source": [
    "# Add 2-pixel padding to the height and width dimensions of the x_training data and normalize the pixel values to be between 0 and 1\n",
    "X_train = tf.pad(X_train, [[0,0], [2,2], [2,2]])/255 \n",
    "\n",
    "# Expand the dimensions of x_train to add an extra channel dimension\n",
    "X_train = tf.expand_dims(X_train, axis=3, name=None)\n",
    "\n",
    "# Repeat x_train 3 times along the channel axis to mimic RGB channels\n",
    "X_train = tf.repeat(X_train, 3, axis=3)\n",
    "\n",
    "# Perform the same operations on the testing data\n",
    "X_test = tf.pad(X_test, [[0,0], [2,2], [2,2]])/255\n",
    "X_test = tf.expand_dims(X_test, axis=3, name=None)\n",
    "X_test = tf.repeat(X_test, 3, axis=3)\n",
    "\n",
    "# Split the last 2000 examples from the x_training data to be used as validation data\n",
    "X_val = X_train[-2000:, :, :, :]\n",
    "y_val = y_train[-2000:]\n",
    "\n",
    "# The remaining data is kept for x_training\n",
    "X_train = X_train[:-2000, :, :, :]\n",
    "y_train = y_train[:-2000]\n",
    "\n",
    "# Print the shapes of the datasets to check everything went as expected\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f191623",
   "metadata": {
    "executionInfo": {
     "elapsed": 629,
     "status": "aborted",
     "timestamp": 1686497683997,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "5f191623"
   },
   "outputs": [],
   "source": [
    "# 3. Loading Pretrained VGG Model\n",
    "base_model = tf.keras.applications.VGG16(weights = 'imagenet',\n",
    "                                         include_top=False,\n",
    "                                         input_shape = (32,32,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Corrected indentation\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1000, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation = 'softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ef538",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1686497683998,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "a10ef538"
   },
   "outputs": [],
   "source": [
    "# 4. Compile and Train Model\n",
    "head_model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "head_model.compile(optimizer = 'adam', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n",
    "\n",
    "history = head_model.fit(X_train, y_train, batch_size=64, epochs=10, validation_data = (X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4a2e7",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1686497683999,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "8bc4a2e7"
   },
   "outputs": [],
   "source": [
    "# 5. Plot Learning Curve\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6,6))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].plot(history.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d822a",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1686497684000,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "183d822a"
   },
   "outputs": [],
   "source": [
    "# 6. Evaluate Test Accuracy\n",
    "\n",
    "score = head_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\", \"Test Accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7fda8",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1686497684002,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "2ee7fda8"
   },
   "outputs": [],
   "source": [
    "# 7. Finetune (unfreeze):\n",
    "\n",
    "## unfreezing\n",
    "base_model = tf.keras.applications.VGG16(weights = 'imagenet',\n",
    "                                         include_top=False,\n",
    "                                         input_shape = (32,32,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672b703",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1686497684003,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "1672b703"
   },
   "outputs": [],
   "source": [
    "print(\"Number of layers in the base model:\", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277dd9f",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1686497684004,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "e277dd9f"
   },
   "outputs": [],
   "source": [
    "fine_tune_at = 10\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1000, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138a995",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "aborted",
     "timestamp": 1686497684005,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "d138a995"
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636309e7",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1686497684006,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "636309e7"
   },
   "outputs": [],
   "source": [
    "len(base_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27bcdc",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "aborted",
     "timestamp": 1686497684008,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "5f27bcdc"
   },
   "outputs": [],
   "source": [
    "#  8. Compile and Train the Model\n",
    "\n",
    "head_model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "head_model.compile(optimizer = 'adam', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb6c81",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "aborted",
     "timestamp": 1686497684010,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "d8cb6c81"
   },
   "outputs": [],
   "source": [
    "history_fine = head_model.fit(X_train, y_train, batch_size=64, epochs=10, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb34ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1686497684011,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "82cb34ad"
   },
   "outputs": [],
   "source": [
    "# 9. Plot Learning Curve\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6,6))\n",
    "\n",
    "axs[0].plot(history_fine.history['loss'])\n",
    "axs[0].plot(history_fine.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "axs[1].plot(history_fine.history['accuracy'])\n",
    "axs[1].plot(history_fine.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a8814",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "aborted",
     "timestamp": 1686497684013,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "038a8814"
   },
   "outputs": [],
   "source": [
    "# 10. Evaluate the Test Accuracy\n",
    "\n",
    "test_loss, test_acc = head_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"\\n\", \"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549ebfe",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "aborted",
     "timestamp": 1686497684014,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "e549ebfe"
   },
   "outputs": [],
   "source": [
    "# 11. Make prediction on the test dataset\n",
    "\n",
    "probability_model = tf.keras.Sequential([head_model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e08148",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "aborted",
     "timestamp": 1686497684015,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "e6e08148"
   },
   "outputs": [],
   "source": [
    "class_names = ['Vehicle', 'Non-vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40a89c",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "aborted",
     "timestamp": 1686497684015,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "4d40a89c"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    true_label, img = true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color='blue'\n",
    "    else:\n",
    "        color='red'\n",
    "    \n",
    "    plt.xlabel('{} {:2.0f}% ({})'.format(class_names[predicted_label], 100*np.max(predictions_array), \n",
    "                                         class_names[true_label], color=color))\n",
    "    \n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = true_label[i]\n",
    "    plt.grid(range(10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color = '#777777')\n",
    "    plt.ylim([0,1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cb4db",
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "aborted",
     "timestamp": 1686497684016,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "105cb4db"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "num_images = num_rows * num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], y_test, X_test)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], y_test)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2c355",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "aborted",
     "timestamp": 1686497684016,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "bfc2c355"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd8ff9",
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "aborted",
     "timestamp": 1686497684017,
     "user": {
      "displayName": "Ethan Rai",
      "userId": "16442066337407392647"
     },
     "user_tz": -600
    },
    "id": "3afd8ff9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
